{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf50610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn as randn\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms as trns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from schedulefree.adamw_schedulefree import AdamWScheduleFree\n",
    "from pytorch_msssim import ssim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "\n",
    "from unet_model import UNet\n",
    "from unet_model import build_xy_coordinates, sinusoidal_2d\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88dce1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb_dim = 16\n",
    "xs, ys = build_xy_coordinates(28,28)\n",
    "pos = sinusoidal_2d(xs, ys, dim=pos_emb_dim).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04dfaeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, loss, dataloader, train_with_cond=False, T = 32):\n",
    "    model.train()\n",
    "    ema_loss = 0\n",
    "    rng_state = torch.get_rng_state()\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    with tqdm(dataloader, desc=f\"Epoch {epoch}\", smoothing=0.01, disable=True) as pbar:\n",
    "\n",
    "        for i, (img, cond) in enumerate(dataloader):\n",
    "            # img ~ Image, z ~ N\n",
    "\n",
    "            img = img.to(DEVICE)\n",
    "            cond = cond.to(DEVICE).long()\n",
    "            z = torch.randn_like(img).to(DEVICE)\n",
    "            \n",
    "            #### global ####\n",
    "                        \n",
    "            # t ~ global slices :\n",
    "            #   (training)\n",
    "            #   img_t = img_0 + (z - img_0) * t\n",
    "            #   model_gloabl(img_t, t) = img_0 - z\n",
    "            #   (generation)\n",
    "            #   img_t-dt = img_t + model_global(img_t, t) * dt\n",
    "            \n",
    "            t = torch.sigmoid(torch.randn(img.shape[0])).to(DEVICE)\n",
    "            img_t = img * (1 - t.view(-1, 1, 1, 1)) + z * t.view(-1, 1, 1, 1)\n",
    "            target = img - z\n",
    "\n",
    "            pos_exp = pos.expand(img.shape[0], -1, -1, -1) \n",
    "            img_emb = torch.cat([img_t, pos_exp], dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y = model(img_emb, t, cond = cond if train_with_cond else None).view(img.shape)\n",
    "            eps_pred = img_t - (1 - t.view(-1, 1, 1, 1)) * y\n",
    "            img0_pred = img_t + t.view(-1, 1, 1, 1) * y\n",
    "\n",
    "            l = loss(y, target) + loss(eps_pred, z) + loss(img0_pred, img)\n",
    "            l.backward()\n",
    "            # all_grads = []\n",
    "            # for param in model.parameters():\n",
    "            #     if param.grad is not None:\n",
    "            #         all_grads.append(param.grad.view(-1))  # Flatten and collect\n",
    "\n",
    "            # # Compute average and max gradient\n",
    "            # if all_grads:\n",
    "            #     all_grads = torch.cat(all_grads)  # Concatenate all gradients into one tensor\n",
    "            #     avg_grad = all_grads.mean().item()  # Compute mean\n",
    "            #     max_grad = all_grads.abs().max().item()  # Compute max absolute gradient\n",
    "            #     print(f\"Epoch {epoch+1}: Avg Gradient = {avg_grad:.6f}, Max Gradient = {max_grad:.6f}\")\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            ema_decay = min(0.99, i / 100)\n",
    "            ema_loss = ema_decay * ema_loss + (1 - ema_decay) * l.item()\n",
    "            \n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\"loss\": ema_loss})\n",
    "    \n",
    "    torch.save(model.state_dict(), \"./mnist-gen/mnist-gen-global.pth\")\n",
    "\n",
    "\n",
    "def test(epoch, model, gen_with_cond=False, T=32, save_dir='./unet/mnist-results_alphablend_test'):\n",
    "    rng_state = torch.get_rng_state()\n",
    "    torch.manual_seed(0)\n",
    "    model.eval()\n",
    "    IMAGE_COUNT = 16 * 16\n",
    "    with torch.no_grad():\n",
    "        pred_x = torch.randn(IMAGE_COUNT, 1, 28, 28).to(DEVICE)\n",
    "        cond = torch.arange(IMAGE_COUNT).long().to(DEVICE) % 10\n",
    "        t = torch.ones(IMAGE_COUNT,).to(DEVICE)\n",
    "        pos_exp = pos.expand(IMAGE_COUNT, -1, -1, -1) \n",
    "        \n",
    "        STEPS = T\n",
    "        for i in range(STEPS):\n",
    "            pred_emb = torch.cat([pred_x, pos_exp], dim=1)\n",
    "            pred = model(pred_emb, t, cond = cond if gen_with_cond else None)\n",
    "            pred_x = pred_x + pred * (1 / STEPS)\n",
    "            t = t - (1 / STEPS)\n",
    "\n",
    "\n",
    "    #print(torch.min(pred), torch.max(pred))\n",
    "    pred_x = pred_x.reshape(16, 16, 28, 28).permute(0, 2, 1, 3)\n",
    "    pred_x = pred_x.reshape(16 * 28, 16 * 28).cpu().numpy()\n",
    "    pred_x = (pred_x * 255).clip(0, 255).astype(np.uint8)\n",
    "    pred_x = Image.fromarray(pred_x)\n",
    "    pred_x.save(f\"{save_dir}/gen-{epoch}.png\")\n",
    "    torch.set_rng_state(rng_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935294fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:11<00:00, 12.76s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    save_dir = './unet/mnist-results_alphablend_test'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    DEVICE = \"cuda\"\n",
    "    CLASSES = None\n",
    "    EPOCHS = 15\n",
    "    T = 32\n",
    "    # transform = trns.Compose([trns.ToTensor(), trns.Normalize((0.5,), (0.5,))])\n",
    "    transform = trns.Compose([trns.ToTensor(),])\n",
    "    dataset = MNIST(\"./data\", download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=512,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    model = UNet(in_channels=1 + pos_emb_dim*2, out_channels=1, emb_dim = 512, num_classes=CLASSES).to(DEVICE)\n",
    "    # print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    optimizer = AdamWScheduleFree(\n",
    "        model.parameters(), 1e-3, weight_decay=0.001, warmup_steps=100\n",
    "    )\n",
    "    loss = nn.MSELoss()\n",
    "\n",
    "    for i in trange(EPOCHS):\n",
    "        test(i, model, gen_with_cond=bool(CLASSES), T=T, save_dir=save_dir)\n",
    "        optimizer.train()\n",
    "        train(i, model, optimizer, loss, dataloader, train_with_cond=bool(CLASSES), T=T)\n",
    "        optimizer.eval()\n",
    "    test(i + 1, model, gen_with_cond=bool(CLASSES), T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48064d68-642b-4efb-ba5d-aa69eabadaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qutip-env-1 [~/.conda/envs/qutip-env-1/]",
   "language": "python",
   "name": "conda_qutip-env-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
